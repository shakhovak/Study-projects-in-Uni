{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72cad37f",
   "metadata": {},
   "source": [
    "# Token Classification. Практическое задание (PJ)\n",
    "\n",
    "Для закрепления материала модуля вам необходимо решить задачу NER для предоставленного датасета, используя любые доступные вам средства. Модель должна обучаться на файле train.txt, валидироваться на файле dev.txt, а её качество необходимо оценить на файле test.txt.\n",
    "\n",
    "Для достижения наилучшего результата уделите внимание подбору гиперпарметров как в плане архитектуры, так и в плане обучения модели.\n",
    "\n",
    "<hr>\n",
    "**Критерии оценивания проекта:**\n",
    "\n",
    "- [x] общее качество кода и следование PEP-8;\n",
    "- [ ] использование рекуррентных сетей;\n",
    "- [x] использованы варианты архитектур, близкие к state of the art для данной задачи;\n",
    "- [x] произведен подбор гиперпараметров;\n",
    "- [x] использованы техники изменения learning rate (lr scheduler);\n",
    "- [x] использована адекватная задаче функция потерь;\n",
    "- [x] использованы техники регуляризации;\n",
    "- [x] корректно проведена валидация модели;\n",
    "- [ ] использованы техники ensemble;\n",
    "- [ ] использованы дополнительные данные;\n",
    "- [x] итоговое значение метрики качества > 0.6 (f1).\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c53779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e5576",
   "metadata": {},
   "source": [
    "Прочитаем файлы и посмотрим, сколько какие NER-tags есть в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc6e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt', 'r', encoding=\"utf-8\") as train:\n",
    "    train_words = train.readlines()\n",
    "with open('dev.txt', 'r', encoding=\"utf-8\") as dev:\n",
    "    dev_words = dev.readlines()\n",
    "with open('test.txt', 'r', encoding=\"utf-8\") as test:\n",
    "    test_words = test.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6d37443",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = []\n",
    "for word in train_words:\n",
    "    if word != '\\n':\n",
    "        token, tag = word.split(' ')\n",
    "        tags.append(tag.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3361110",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in dev_words:\n",
    "    if word != '\\n':\n",
    "        token, tag = word.split(' ')\n",
    "        tags.append(tag.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "298b0299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'O': 176027,\n",
       "         'B-PER': 8469,\n",
       "         'B-ORG': 6713,\n",
       "         'I-ORG': 4413,\n",
       "         'B-LOC': 5729,\n",
       "         'I-LOC': 1279,\n",
       "         'I-PER': 5246})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1b2c12",
   "metadata": {},
   "source": [
    "Очевиден дисбаланс классов, но для трансофрмерных моделей не будем здесь ничего делать, они должны справиться без проблем.\n",
    "\n",
    "В отдельный словарь выведем лейблы ner и присвоенные им цифровые значения. Воспользуемся готовым словарем из интернета, так имеющиеся данные не отличаются от них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d886e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'O': 0,\n",
    " 'B-PER': 1,\n",
    " 'I-PER': 2,\n",
    " 'B-ORG': 3,\n",
    " 'I-ORG': 4,\n",
    " 'B-LOC': 5,\n",
    " 'I-LOC': 6,\n",
    " 'B-MISC': 7,\n",
    " 'I-MISC': 8}\n",
    "\n",
    "id2label={0: 'O',\n",
    " 1: 'B-PER',\n",
    " 2: 'I-PER',\n",
    " 3: 'B-ORG',\n",
    " 4: 'I-ORG',\n",
    " 5: 'B-LOC',\n",
    " 6: 'I-LOC',\n",
    " 7: 'B-MISC',\n",
    " 8: 'I-MISC'}\n",
    "\n",
    "label_list = list(label2id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b6b11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef22c98c",
   "metadata": {},
   "source": [
    "Обработаем загруженные файлы:\n",
    "- разобъем их на предолжения по знаку \\n\n",
    "- для каждого предложения в отдельный список соберем его токены и ner_tags\n",
    "- ner_tags заменим на его цифровое значение\n",
    "- переведем все 3 файла в формате dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09f7ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(lst):\n",
    "    temp_list_tokens = []\n",
    "    temp_list_ner_tags = []\n",
    "    res = []\n",
    "    count = 0\n",
    "    for word in lst:\n",
    "        if word == '\\n':\n",
    "            res.append({'id': count,\n",
    "                        'tokens': temp_list_tokens,\n",
    "                        'ner_tags': temp_list_ner_tags\n",
    "                \n",
    "            })\n",
    "            temp_list_tokens = []\n",
    "            temp_list_ner_tags = []\n",
    "            count += 1\n",
    "        else:\n",
    "            token, ner_tag = word.split(' ')\n",
    "            if token not in label_list:\n",
    "                temp_list_tokens.append(token)\n",
    "                temp_list_ner_tags.append(label2id[ner_tag.replace('\\n', '')])\n",
    "\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa948ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 7746\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 2582\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'ner_tags'],\n",
       "        num_rows: 2582\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import datasets\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(pd.DataFrame(split_into_sentences(train_words))),\n",
    "    \"valid\": Dataset.from_pandas(pd.DataFrame(split_into_sentences(dev_words))),\n",
    "    'test': Dataset.from_pandas(pd.DataFrame(split_into_sentences(test_words)))\n",
    "    })\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d02bc19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"_______________________________________0\n",
      "Если____________________________________0\n",
      "Миронов_________________________________1\n",
      "занял___________________________________0\n",
      "столь___________________________________0\n",
      "оппозиционную___________________________0\n",
      "позицию_________________________________0\n",
      ",_______________________________________0\n",
      "то______________________________________0\n",
      "мне_____________________________________0\n",
      "представляется__________________________0\n",
      ",_______________________________________0\n",
      "что_____________________________________0\n",
      "для_____________________________________0\n",
      "него____________________________________0\n",
      "было____________________________________0\n",
      "бы______________________________________0\n",
      "порядочным______________________________0\n",
      "и_______________________________________0\n",
      "правильным______________________________0\n",
      "уйти____________________________________0\n",
      "в_______________________________________0\n",
      "отставку________________________________0\n",
      "с_______________________________________0\n",
      "занимаемого_____________________________0\n",
      "им______________________________________0\n",
      "поста___________________________________0\n",
      ",_______________________________________0\n",
      "поста___________________________________0\n",
      ",_______________________________________0\n",
      "который_________________________________0\n",
      "предоставлен____________________________0\n",
      "ему_____________________________________0\n",
      "сегодня_________________________________0\n",
      "\"_______________________________________0\n",
      "Единой__________________________________3\n",
      "Россией_________________________________4\n",
      "''______________________________________0\n",
      "и_______________________________________0\n",
      "никем___________________________________0\n",
      "больше__________________________________0\n",
      "''______________________________________0\n",
      ",_______________________________________0\n",
      "-_______________________________________0\n",
      "заключает_______________________________0\n",
      "Исаев___________________________________1\n",
      "._______________________________________0\n"
     ]
    }
   ],
   "source": [
    "for token, ner_tag in zip(dataset['train'][0]['tokens'], dataset['train'][0]['ner_tags']):\n",
    "    print(f'{token:_<40}{ner_tag}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e363ad3d",
   "metadata": {},
   "source": [
    "Все вроде бы хорошо, но есть небольшая техническая трудность, на которую надо обратить внимание при решении подобных задач. При токенизации, например, с помощью алгоритма WordPiece, часть слов может быть разбита на несколько токенов. Количество токенов перестанет совпадать с количеством классов для текста. То же самое касается специальных токенов, таких как [CLS], [SEP] и токенов для паддинга [PAD].\n",
    "\n",
    "Придется использовать дополнительную функцию для выравнивания длины токенов после токенизатора.\n",
    "\n",
    "Воспользуюсь русскоязычной моделью https://huggingface.co/DeepPavlov/rubert-base-cased\n",
    "\n",
    "Посмотрим на пример одного предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d18b753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e04ca33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token len from BERT tokenizer__53\n",
      "Token len initial tokens__47\n",
      "\n",
      "[CLS] \" Если Миронов занял столь оппозиционную позицию , то мне представляется , что для него было бы поряд ##очным и правильным уйти в отставку с заним ##аемого им поста , поста , который предоставлен ему сегодня \" Единой Россией ' ' и никем больше ' ' , - заключает Исаев . [SEP]\n"
     ]
    }
   ],
   "source": [
    "example = dataset[\"train\"][0]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "\n",
    "print(f'Token len from BERT tokenizer__{len(tokens)}')\n",
    "print(f'Token len initial tokens__{len(example[\"tokens\"])}\\n')\n",
    "\n",
    "print(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a74dc480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9117b3c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7746 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2582 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2582 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 7746\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2582\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2582\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True,\n",
    "                               remove_columns = ['id', 'tokens', 'ner_tags'])\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37134407",
   "metadata": {},
   "source": [
    "Посмотрим, как после функции проставились токены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27ccdc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]___________________________________-100\n",
      "\"_______________________________________0\n",
      "Если____________________________________0\n",
      "Миронов_________________________________1\n",
      "занял___________________________________0\n",
      "столь___________________________________0\n",
      "оппозиционную___________________________0\n",
      "позицию_________________________________0\n",
      ",_______________________________________0\n",
      "то______________________________________0\n",
      "мне_____________________________________0\n",
      "представляется__________________________0\n",
      ",_______________________________________0\n",
      "что_____________________________________0\n",
      "для_____________________________________0\n",
      "него____________________________________0\n",
      "было____________________________________0\n",
      "бы______________________________________0\n",
      "поряд___________________________________0\n",
      "##очным_________________________________-100\n",
      "и_______________________________________0\n",
      "правильным______________________________0\n",
      "уйти____________________________________0\n",
      "в_______________________________________0\n",
      "отставку________________________________0\n",
      "с_______________________________________0\n",
      "заним___________________________________0\n",
      "##аемого________________________________-100\n",
      "им______________________________________0\n",
      "поста___________________________________0\n",
      ",_______________________________________0\n",
      "поста___________________________________0\n",
      ",_______________________________________0\n",
      "который_________________________________0\n",
      "предоставлен____________________________0\n",
      "ему_____________________________________0\n",
      "сегодня_________________________________0\n",
      "\"_______________________________________0\n",
      "Единой__________________________________3\n",
      "Россией_________________________________4\n",
      "'_______________________________________0\n",
      "'_______________________________________-100\n",
      "и_______________________________________0\n",
      "никем___________________________________0\n",
      "больше__________________________________0\n",
      "'_______________________________________0\n",
      "'_______________________________________-100\n",
      ",_______________________________________0\n",
      "-_______________________________________0\n",
      "заключает_______________________________0\n",
      "Исаев___________________________________1\n",
      "._______________________________________0\n",
      "[SEP]___________________________________-100\n"
     ]
    }
   ],
   "source": [
    "for token, label in zip(tokenizer.convert_ids_to_tokens(tokenized_dataset['train'][0]['input_ids']), \n",
    "                        tokenized_dataset['train'][0]['labels']):\n",
    "    print(f'{token:_<40}{label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da66e2",
   "metadata": {},
   "source": [
    "Воспользуемся метрикой качества seqeval https://huggingface.co/spaces/evaluate-metric/seqeval\n",
    "\n",
    "<hr>\n",
    "**For info:** seqeval is a Python framework for sequence labeling evaluation. seqeval can evaluate the performance of chunking tasks such as named-entity recognition, part-of-speech tagging, semantic role labeling and so on.\n",
    "\n",
    "Overall:\n",
    "- accuracy: the average accuracy, on a scale between 0.0 and 1.0.\n",
    "- precision: the average precision, on a scale between 0.0 and 1.0.\n",
    "- recall: the average recall, on a scale between 0.0 and 1.0.\n",
    "- f1: the average F1 score, which is the harmonic mean of the precision and recall. It also has a scale of 0.0 to 1.0.\n",
    "<hr>\n",
    "\n",
    "Далее "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7afa3ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7448a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4af5cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f827d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_VALUES = (2e-5, 5e-5)\n",
    "DECAY_VALUES = (1e-4, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e1b9d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log: training for l_r:2e-05, w_d:0.0001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1455' max='1455' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1455/1455 02:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.025560</td>\n",
       "      <td>0.952201</td>\n",
       "      <td>0.966999</td>\n",
       "      <td>0.959543</td>\n",
       "      <td>0.992415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>0.027997</td>\n",
       "      <td>0.959257</td>\n",
       "      <td>0.971220</td>\n",
       "      <td>0.965202</td>\n",
       "      <td>0.992886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.020558</td>\n",
       "      <td>0.968702</td>\n",
       "      <td>0.973906</td>\n",
       "      <td>0.971297</td>\n",
       "      <td>0.994512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log: training for l_r:2e-05, w_d:0.1...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1455' max='1455' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1455/1455 02:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.025463</td>\n",
       "      <td>0.956546</td>\n",
       "      <td>0.967191</td>\n",
       "      <td>0.961839</td>\n",
       "      <td>0.992748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.205400</td>\n",
       "      <td>0.026577</td>\n",
       "      <td>0.963273</td>\n",
       "      <td>0.971220</td>\n",
       "      <td>0.967230</td>\n",
       "      <td>0.993513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.021147</td>\n",
       "      <td>0.970218</td>\n",
       "      <td>0.975058</td>\n",
       "      <td>0.972632</td>\n",
       "      <td>0.994336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log: training for l_r:5e-05, w_d:0.0001...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1455' max='1455' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1455/1455 02:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.030848</td>\n",
       "      <td>0.948133</td>\n",
       "      <td>0.964505</td>\n",
       "      <td>0.956249</td>\n",
       "      <td>0.992082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.148000</td>\n",
       "      <td>0.020419</td>\n",
       "      <td>0.965983</td>\n",
       "      <td>0.975249</td>\n",
       "      <td>0.970594</td>\n",
       "      <td>0.994493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.018788</td>\n",
       "      <td>0.971855</td>\n",
       "      <td>0.973906</td>\n",
       "      <td>0.972880</td>\n",
       "      <td>0.995179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log: training for l_r:5e-05, w_d:0.1...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1455' max='1455' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1455/1455 02:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.028757</td>\n",
       "      <td>0.956029</td>\n",
       "      <td>0.971988</td>\n",
       "      <td>0.963943</td>\n",
       "      <td>0.993042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.966337</td>\n",
       "      <td>0.974866</td>\n",
       "      <td>0.970583</td>\n",
       "      <td>0.994003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.018770</td>\n",
       "      <td>0.972828</td>\n",
       "      <td>0.975441</td>\n",
       "      <td>0.974133</td>\n",
       "      <td>0.994983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "for i, learning_rate in enumerate(LR_VALUES):\n",
    "    for j, weight_decay in enumerate(DECAY_VALUES):\n",
    "            \n",
    "            model = AutoModelForTokenClassification.from_pretrained(\n",
    "                \"DeepPavlov/rubert-base-cased\", num_labels=9, id2label=id2label, label2id=label2id)\n",
    "            print(f'Log: training for l_r:{learning_rate}, w_d:{weight_decay}...')\n",
    "            \n",
    "            training_args = TrainingArguments(\n",
    "                output_dir=\"token_class_model\",\n",
    "                learning_rate=learning_rate,\n",
    "                per_device_train_batch_size=16,\n",
    "                per_device_eval_batch_size=16,\n",
    "                num_train_epochs=3,\n",
    "                weight_decay=weight_decay,\n",
    "                evaluation_strategy=\"epoch\",\n",
    "                push_to_hub=False,\n",
    "                save_strategy=\"no\", \n",
    "                group_by_length=True,\n",
    "                warmup_ratio=0.1,\n",
    "                optim=\"adamw_torch\",\n",
    "                lr_scheduler_type=\"cosine\",\n",
    "            )\n",
    "\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=tokenized_dataset[\"train\"],\n",
    "                eval_dataset=tokenized_dataset[\"valid\"],\n",
    "                tokenizer=tokenizer,\n",
    "                data_collator=data_collator,\n",
    "                compute_metrics=compute_metrics,\n",
    "            )\n",
    "\n",
    "            trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eadc951",
   "metadata": {},
   "source": [
    "Итак, в принципе задача NER classification для RuBert на данном датасет оказалась очень легкой. При всех выбранных парах learning_rate + weight decay модель справилась неплохо. Если сравнивать по метрике F1, то немного лучше сработали параметры:\n",
    "\n",
    "- learning rate = 5e-05\n",
    "- weight decay = 0.1\n",
    "\n",
    "Возьмем эти параметры для тестирования на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a691c506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log: training for l_r:5e-05, w_d:0.1...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1455' max='1455' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1455/1455 02:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.028757</td>\n",
       "      <td>0.956029</td>\n",
       "      <td>0.971988</td>\n",
       "      <td>0.963943</td>\n",
       "      <td>0.993042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.966337</td>\n",
       "      <td>0.974866</td>\n",
       "      <td>0.970583</td>\n",
       "      <td>0.994003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.018770</td>\n",
       "      <td>0.972828</td>\n",
       "      <td>0.975441</td>\n",
       "      <td>0.974133</td>\n",
       "      <td>0.994983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1455, training_loss=0.05755561848276669, metrics={'train_runtime': 137.4864, 'train_samples_per_second': 169.02, 'train_steps_per_second': 10.583, 'total_flos': 319955671049400.0, 'train_loss': 0.05755561848276669, 'epoch': 3.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"DeepPavlov/rubert-base-cased\", num_labels=9, id2label=id2label, label2id=label2id)\n",
    "print(f'Log: training for l_r:{learning_rate}, w_d:{weight_decay}...')\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"token_class_model\",\n",
    "    learning_rate=5e-05,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    push_to_hub=False,\n",
    "    save_strategy=\"no\", \n",
    "    group_by_length=True,\n",
    "    warmup_ratio=0.1,\n",
    "    optim=\"adamw_torch\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "127670ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset=tokenized_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d00df0",
   "metadata": {},
   "source": [
    "Для оценки качества на тестовой выборки посмотрим метрику по итогу работы trainer.predict, а также визуально оценим результаты на нескольких текстах. Для этого воспользуемся pipeline из трансформеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c04b1fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.017470069229602814,\n",
       " 'test_precision': 0.9741223307998552,\n",
       " 'test_recall': 0.9812249362012395,\n",
       " 'test_f1': 0.9776607337450054,\n",
       " 'test_accuracy': 0.9954596189863599,\n",
       " 'test_runtime': 5.2869,\n",
       " 'test_samples_per_second': 488.373,\n",
       " 'test_steps_per_second': 30.642}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f514aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12799d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "ner = pipeline(\"ner\", model=model, tokenizer=tokenizer, device = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44d5bbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.99680483,\n",
       "  'index': 3,\n",
       "  'word': 'Шах',\n",
       "  'start': 11,\n",
       "  'end': 14},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9970294,\n",
       "  'index': 4,\n",
       "  'word': '##ова',\n",
       "  'start': 14,\n",
       "  'end': 17},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99362975,\n",
       "  'index': 5,\n",
       "  'word': 'Екатерина',\n",
       "  'start': 18,\n",
       "  'end': 27},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.9964785,\n",
       "  'index': 10,\n",
       "  'word': 'Москвы',\n",
       "  'start': 41,\n",
       "  'end': 47},\n",
       " {'entity': 'B-PER',\n",
       "  'score': 0.9969182,\n",
       "  'index': 16,\n",
       "  'word': 'Ромаш',\n",
       "  'start': 68,\n",
       "  'end': 73},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9354444,\n",
       "  'index': 17,\n",
       "  'word': '##ки',\n",
       "  'start': 73,\n",
       "  'end': 75}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner('Меня зовут Шахова Екатерина и я родом из Москвы, работаю в компании Ромашки')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19b7492a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " [{'entity': 'B-ORG',\n",
       "   'score': 0.58599067,\n",
       "   'index': 1,\n",
       "   'word': 'Yahoo',\n",
       "   'start': 0,\n",
       "   'end': 5}],\n",
       " [],\n",
       " [{'entity': 'B-PER',\n",
       "   'score': 0.60913134,\n",
       "   'index': 1,\n",
       "   'word': 'Кэрол',\n",
       "   'start': 0,\n",
       "   'end': 5}],\n",
       " [{'entity': 'B-PER',\n",
       "   'score': 0.97244275,\n",
       "   'index': 1,\n",
       "   'word': 'Барт',\n",
       "   'start': 0,\n",
       "   'end': 4}],\n",
       " [],\n",
       " [{'entity': 'B-PER',\n",
       "   'score': 0.96958554,\n",
       "   'index': 1,\n",
       "   'word': 'Джерри',\n",
       "   'start': 0,\n",
       "   'end': 6}],\n",
       " [{'entity': 'B-PER',\n",
       "   'score': 0.9828484,\n",
       "   'index': 1,\n",
       "   'word': 'Янга',\n",
       "   'start': 0,\n",
       "   'end': 4}],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(dataset['test'][2]['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e1df4",
   "metadata": {},
   "source": [
    "# Финальные выводы:\n",
    "\n",
    "Задача классификации сущностей оказалась довольно легкой для RuBert, несмотря на серьезный дисбаланс классов. Метрика на тестовом датасете довольно высокая и визуальные примеры показали хороший результаты, хотя компанию Ромашка модель отнесла к персоне, а не к организации."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
