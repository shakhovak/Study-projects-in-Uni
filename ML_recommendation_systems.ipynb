{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c2c1670",
   "metadata": {},
   "source": [
    "# Домашнее задание 7\n",
    "**Памперсы или пиво? Практический проект по созданию рекомендательной системы**\n",
    "\n",
    "**Цель**: Настало время поработать с данными самой большой и самой дорогой компании, занимающейся, похоже, уже всем на свете: от продажи всего и вся, до настройки облачных инфраструктур и создания роботов. Конечно же это компания Джеффа могу-купить-весь-мир Безоса - Amazon.\n",
    "\n",
    "<hr>\n",
    "\n",
    "1. Выберите любой понравившийся вам набор данных по ссылке https://nijianmo.github.io/amazon/index.html. Проведите базовый EDA - распределения рейтингов, количество уникальных товаров и т.д. Отложите часть данных для тестирования. В рекомендательных системах для этого можно случайным образом “занулить” желаемый процент рейтингов в исходном датасете, чтобы получить “тренировочный набор”, и проверять качество ваших рекомендаций на этих уже не зануленных рейтингах. При этом, если у вас есть временная зависимость в данных, имеет смысл занулять рейтинги “из будущего”, чтобы обучаться на “исторических” покупках/просмотрах и т.д. \n",
    "2. На основании вашего датасета постройте рекомендательную систему. Оцените качество полученных рекомендаций, при помощи подходящих метрик (если вы использовали рейтинги, можно взять RMSE).\n",
    "\n",
    "<hr>\n",
    "\n",
    "**Критерии оценки: <li> Базовый EDA - 2 балла. <li> Train-test разбиение - 2 балла. <li> Построение модели и оценка качества - 6 баллов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33a37f9",
   "metadata": {},
   "source": [
    "# 1. Preprocessing and EDA\n",
    "\n",
    "Скачаем один из \"маленьких\"  датасетов, связанных с косметикой. Датасет влючает ID продуктв, ID пользователя, рейтинг и отметка времени. К этому же датасету скачаем метаданные, которые включают текстовое описание продукта. Так будет интереснее смотреть на результаты работы алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c7c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ab8df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0143026860</td>\n",
       "      <td>A1V6B6TNIC10QE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1424304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0143026860</td>\n",
       "      <td>A2F5GHSXFQ0W6J</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1418860800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0143026860</td>\n",
       "      <td>A1572GUYS7DGSR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1407628800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0143026860</td>\n",
       "      <td>A1PSGLFK1NSVO</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1362960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item            user  rating   timestamp\n",
       "0  0143026860  A1V6B6TNIC10QE     1.0  1424304000\n",
       "1  0143026860  A2F5GHSXFQ0W6J     4.0  1418860800\n",
       "2  0143026860  A1572GUYS7DGSR     4.0  1407628800\n",
       "3  0143026860   A1PSGLFK1NSVO     5.0  1362960000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('All_Beauty.csv', header = None, names = ['item', 'user', 'rating', 'timestamp'])\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30110c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>371345</td>\n",
       "      <td>371345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>32586</td>\n",
       "      <td>324038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>B000FOI48G</td>\n",
       "      <td>A2GJX2KCUSR0EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>8672</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              item            user\n",
       "count       371345          371345\n",
       "unique       32586          324038\n",
       "top     B000FOI48G  A2GJX2KCUSR0EI\n",
       "freq          8672              27"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb92cb",
   "metadata": {},
   "source": [
    "Итак, датасет содержит довольно много пользователей и продуктов. Такой датасет (как уже проверяла) в полном размере не помещается в память, поэтому немного его уменьшим, оставим только тех пользователей, кто оставил более 2 отзывов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5494857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23291</td>\n",
       "      <td>23291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5082</td>\n",
       "      <td>6119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>B0012Y0ZG2</td>\n",
       "      <td>A2GJX2KCUSR0EI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2231</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              item            user\n",
       "count        23291           23291\n",
       "unique        5082            6119\n",
       "top     B0012Y0ZG2  A2GJX2KCUSR0EI\n",
       "freq          2231              27"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modified = df[df['user'].isin(df['user'].value_counts()[df['user'].value_counts() > 2].index)]\n",
    "#df_modified = df_modified[df_modified['item'].isin(df_modified['item'].value_counts()[df_modified['item'].value_counts() > 1].index)]\n",
    "\n",
    "df_modified = df_modified.reset_index()\n",
    "df_modified.describe(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb802aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('6546546450', \"Loud 'N Clear&trade; Personal Sound Amplifier\"),\n",
       " ('7178680776', 'No7 Lift &amp; Luminate Triple Action Serum 50ml by Boots'),\n",
       " ('7250468162', 'No7 Stay Perfect Foundation Cool Vanilla by No7'),\n",
       " ('7367905066',\n",
       "  'Wella Koleston Perfect Hair Colour 44/44 Medium Intense Red Brown 60ml'),\n",
       " ('7414204790', 'Lacto Calamine Skin Balance Oil control 120 ml. (Pack of 2)')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "desc = {}\n",
    "\n",
    "with open(\"meta_All_Beauty.json\") as f:\n",
    "    s = f.read()\n",
    "    s = '[' + s + ']'\n",
    "    s = s.replace('\\t','')\n",
    "    s = s.replace('\\n',',')\n",
    "    s = s.replace(',}','}')\n",
    "    s = s.replace(',]',']')\n",
    "    data = json.loads(s)\n",
    "    \n",
    "    desc = {}\n",
    "    for record in data:\n",
    "            id_n = record['asin']\n",
    "            title = record['title']\n",
    "            \n",
    "            desc[id_n] = title\n",
    "list(desc.items())[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daf9057",
   "metadata": {},
   "source": [
    "Создадим функцию для разбивки данных на train/test. Разобъем данные как рекомендую в задании, включать в train только последние по времени 20% данных. При этом добавим константу 0,5, запись попадала в train, если значение индекса будет ноль (иначе будет большой дисбаланс и все записи c 1-2 рейтингами уйдут в test). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8e82481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def train_test_split(df):\n",
    "    df.sort_values(by = 'timestamp', inplace = True)\n",
    "    users_list = df['user'].unique()\n",
    "    #items_list = df['item'].unique()\n",
    "    X_train_list = []\n",
    "    X_test_list = []\n",
    "    y_train_list = []\n",
    "    y_test_list = []\n",
    "    \n",
    "    for user in tqdm_notebook(users_list):\n",
    "        temp = df[df['user'] == user]\n",
    "        indx = int(temp.shape[0] * (1 - 0.2) + 0.5)\n",
    "        #print(indx)\n",
    "        X_train_list.append(temp[['user', 'item']].iloc[:indx, :].values)\n",
    "        X_test_list.append(temp[['user', 'item']].iloc[indx:, :].values)\n",
    "        y_train_list.append(temp['rating'].values[:indx])\n",
    "        y_test_list.append(temp['rating'].values[indx:])\n",
    "        \n",
    "    X_train = pd.DataFrame(np.vstack(X_train_list), columns = ['user', 'item'])\n",
    "    X_test = pd.DataFrame(np.vstack(X_test_list), columns = ['user', 'item'])\n",
    "    y_train = np.hstack(y_train_list)\n",
    "    y_test = np.hstack(y_test_list)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d124c6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56447e0d98c84ddcb506c67ac389ddd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((17050, 2), 17050, (6241, 2), 6241)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_modified)\n",
    "X_train.shape, len(y_train), X_test.shape, len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9582de90",
   "metadata": {},
   "source": [
    "# 2. Создание рекомендательных систем\n",
    "\n",
    "## 2.1 Colloborative explicit filtering\n",
    "\n",
    "Начнем с самой простой и как раз уменьшенные данные пригодятся. При больших кол-вах пользователей и продуктов не зватило памяти для подсчета близости.\n",
    "\n",
    "Будем использовать user-based model, которая подразумевает поиск схожести пользователей на основе вектора их рейтингов. По оценкам схожих пользователей считается рейтинг для продуктов у искомого пользователя. Для расчета прогнозного рейтинга будем использовать формулу, предложенную на лекции:\n",
    "\n",
    "$$\n",
    "    r_{ui} = \\overline{r_u} + \\frac\n",
    "    {\\sum_{v \\in User_i}\\big(\\textit{sim(u, v)} \\times (r_{vi} - \\overline{r_v})\\big)}\n",
    "    {\\sum_{v \\in User_i}\\textit{|sim(u, v)|}}\n",
    "$$\n",
    "\n",
    "#### Шаг 1. \n",
    "Посчитаем средний рейтинг по каждому пользователю и вычетм его из всех его рейтингов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d39e2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.copy()\n",
    "users = X['user'].unique()\n",
    "items = X['item'].unique()\n",
    "X['y'] = y_train\n",
    "mean_user = X.groupby('user')['y'].mean()\n",
    "X['y'] -= X['user'].apply(lambda x: mean_user[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26abcf7",
   "metadata": {},
   "source": [
    "#### Шаг 2. \n",
    "Создадим матрицу user/item, кол-во строк которой - кол-во уникальных пользователей, кол-во стобцов - кол-во уникальных продуктов. Получиться большая разреженная матрица.\n",
    "Для этой же матрицы посчитаем схожесть каждого пользователя с каждым по вектору их рейтингов. В результате будет массив, где кол-во строк и стобцов равно кол-ву уникальных пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea43bdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User/item matrix shape: (6119, 3960)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item</th>\n",
       "      <th>0992916305</th>\n",
       "      <th>1465042776</th>\n",
       "      <th>1465045953</th>\n",
       "      <th>1620213982</th>\n",
       "      <th>4293845755</th>\n",
       "      <th>9742121109</th>\n",
       "      <th>9790787006</th>\n",
       "      <th>B000050B63</th>\n",
       "      <th>B000050B65</th>\n",
       "      <th>B000050B6B</th>\n",
       "      <th>...</th>\n",
       "      <th>B01HBWYB5Y</th>\n",
       "      <th>B01HBXID8Y</th>\n",
       "      <th>B01HCPNYR6</th>\n",
       "      <th>B01HD23OJG</th>\n",
       "      <th>B01HE4QV52</th>\n",
       "      <th>B01HFLLNXE</th>\n",
       "      <th>B01HG2R3KE</th>\n",
       "      <th>B01HHWBYNK</th>\n",
       "      <th>B01HIPOQ2M</th>\n",
       "      <th>B01HIWLLUK</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A100UD67AHFODS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A100WO06OQR8BQ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 3960 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item            0992916305  1465042776  1465045953  1620213982  4293845755  \\\n",
       "user                                                                         \n",
       "A100UD67AHFODS           0           0           0         0.0           0   \n",
       "A100WO06OQR8BQ           0           0           0         0.0           0   \n",
       "\n",
       "item            9742121109  9790787006  B000050B63  B000050B65  B000050B6B  \\\n",
       "user                                                                         \n",
       "A100UD67AHFODS           0         0.0           0         0.0           0   \n",
       "A100WO06OQR8BQ           0         0.0           0         0.0           0   \n",
       "\n",
       "item            ...  B01HBWYB5Y  B01HBXID8Y  B01HCPNYR6  B01HD23OJG  \\\n",
       "user            ...                                                   \n",
       "A100UD67AHFODS  ...         0.0           0         0.0         0.0   \n",
       "A100WO06OQR8BQ  ...         0.0           0         0.0         0.0   \n",
       "\n",
       "item            B01HE4QV52  B01HFLLNXE  B01HG2R3KE  B01HHWBYNK  B01HIPOQ2M  \\\n",
       "user                                                                         \n",
       "A100UD67AHFODS           0           0           0         0.0         0.0   \n",
       "A100WO06OQR8BQ           0           0           0         0.0         0.0   \n",
       "\n",
       "item            B01HIWLLUK  \n",
       "user                        \n",
       "A100UD67AHFODS         0.0  \n",
       "A100WO06OQR8BQ         0.0  \n",
       "\n",
       "[2 rows x 3960 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vectors = pd.pivot_table(X, values = 'y', index = 'user', columns = 'item',\n",
    "                             fill_value = 0)\n",
    "print(f'User/item matrix shape: {user_vectors.shape}')\n",
    "user_vectors.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daccd9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User similarity matrix shape: (6119, 6119)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "user_sim = cosine_similarity(user_vectors)\n",
    "print(f'User similarity matrix shape: {user_sim.shape}')\n",
    "user_sim[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e6c8cb",
   "metadata": {},
   "source": [
    "#### Шаг 3. \n",
    "Подсчитаем позицию каждого пользователя в матрице user/item - это нужно для формулы предсказания рейтинга. Постороим функцию для прогноза рейтинга. Предскажим рейтинг для тестового набора и посмотрим не метрики для оценки качества регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51761455",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pos = dict()\n",
    "for user in users:\n",
    "    user_pos[user] = np.argwhere(user_vectors.index.values == user)[0][0]\n",
    "    \n",
    "def predict_rating(user, item):\n",
    "\n",
    "    if not item in items or not user in users:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "    numerator = user_sim[user_pos[user]].dot(\n",
    "                    user_vectors.loc[:, item])\n",
    "    \n",
    "    denominator = round(np.abs(user_sim[user_pos[user]]).sum() - 1, 4) \n",
    "    # округлим до 4-х знаков, а то очень малые числа в знаменателе могут дать очень большие числа для к-та\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "\n",
    "    return mean_user[user] + numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "395c9b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Colloborative explicit filtering 2.1926\n",
      "MAE Colloborative explicit filtering 1.2391\n",
      "MAPE Colloborative explicit filtering 0.3513\n",
      "R2 Colloborative explicit filtering -2.8438\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "y_pred = X_test[['user', 'item']].apply(lambda row: predict_rating(row[0], row[1]), axis = 1)\n",
    "\n",
    "print(f'RMSE Colloborative explicit filtering {round(np.sqrt(mean_squared_error(y_test, y_pred)),4)}')\n",
    "print(f'MAE Colloborative explicit filtering {round(mean_absolute_error(y_test, y_pred),4)}')\n",
    "print(f'MAPE Colloborative explicit filtering {round(mean_absolute_percentage_error(y_test, y_pred),4)}')\n",
    "print(f'R2 Colloborative explicit filtering {round(r2_score(y_test, y_pred),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdf41a8",
   "metadata": {},
   "source": [
    "Результаты конечно не очень хорошие, в среднем не тестовом датасете алгоритм ошибается на 2 пункта. Посмотрим, как выглядят точечные рекомедации для пользователей. Будем брать только тех, которые были в трейн сете, так как алгоритм не знает новых пользователей.\n",
    "\n",
    "Будем перебирать все товары в трейн-сете для конткретного пользователя, затем из отберем топ-рекомендации - все больше 3.\n",
    "\n",
    "Для новых пользователей это может быть отдельное правило, например, топ-5 по рекомендациям в категории."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "458a7466",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_list = X_train['user'].unique()\n",
    "train_item_list = X_train['item'].unique()\n",
    "\n",
    "def make_prediction(user):\n",
    "    ratings_pred = {}\n",
    "\n",
    "    for i in train_item_list:\n",
    "        rating = predict_rating(user, i)\n",
    "        if rating > 3:\n",
    "            ratings_pred[i] = rating\n",
    "\n",
    "    purchase_list = df_modified[df_modified['user'] == user]['item'].values\n",
    "\n",
    "    print('Purchased:')\n",
    "    for item in purchase_list:\n",
    "        try:\n",
    "            print(f'***{desc[item][:100]}')\n",
    "        except:\n",
    "            print(item)\n",
    "            \n",
    "    print('\\n')\n",
    "    print(f'Recomendations:')\n",
    "    \n",
    "    sorted_recs = []\n",
    "    for i in sorted(ratings_pred, key=ratings_pred.get, reverse=True):\n",
    "        if i in purchase_list:\n",
    "            pass\n",
    "        else:\n",
    "            sorted_recs.append(i)\n",
    "            \n",
    "    for recom in sorted_recs[:5]:\n",
    "       try:\n",
    "            print(f'***{desc[recom][:100]}')\n",
    "       except:\n",
    "            print(recom)\n",
    "            \n",
    "    return list(ratings_pred.items())[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bb0b80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purchased:\n",
      "***Gillette Venus &amp; Olay Sugarberry Scent Women's Razor Blade Refills 3 Count\n",
      "***NARS Blush, Gaiety\n",
      "***NARS Blush, Taj Mahal\n",
      "\n",
      "\n",
      "Recomendations:\n",
      "***Norelco 6885XL Deluxe Quadra Action Cord/Cordless Rechargeable Men's Shaver\n",
      "***Braun Clean &amp; Renew Refill Cartridges CCR - 2 Count (Packaging May Vary)\n",
      "***Braun 8000 Activator Combi-Pack Foil and Cutterblock Replacement Parts for Braun's Activator Razor M\n",
      "***Norelco 6826XL Quadra Action Cord/Cordless Rechargeable Men's Shaver\n",
      "***Method Hand Wash, Pomegranate - 12 fl oz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('B000050B65', 5.0),\n",
       " ('B000050FDY', 5.0),\n",
       " ('B0002MQ9GK', 5.0),\n",
       " ('B000050B63', 5.0),\n",
       " ('B00027D5H6', 5.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "make_prediction(random.choice(train_user_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5f44082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purchased:\n",
      "***Fresh Guard Wipes Specially Formulated for Retainers Mouthguards and Removable Braces, 20 Count\n",
      "***dr. brandt Cellusculpt, 6.3 fl. oz.\n",
      "***Head and Shoulders Green Apple 2-In-1 Dandruff Shampoo And Conditioner 23.7 F\n",
      "***MHU Professional Folding Blow Dryer 1875w Negative Ion Hair Dryer Dual Voltage Dc Motor Lightweight \n",
      "***Star Tech Professional Grade Lady Beauty Tool Eyelash Curler (Pink)\n",
      "***Neutrogena Healthy Defense Daily Moisturizer Sensitive Skin, SPF 50 Lotion 1.70 oz\n",
      "\n",
      "\n",
      "Recomendations:\n",
      "***essie nail polish, cuticle care, primers and finishers\n",
      "***essie Gel Couture Nail Polish\n",
      "***Pantene Pro-V Volume Conditioner 12.0 Fluid Ounce (Product Size May Vary)\n",
      "***Gillette M3 Power Cartridges 8 Count\n",
      "***Toni&amp;Guy Glamour Volume Plumping Whip, 2.82 Fluid Ounce\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('B000050B65', 4.8),\n",
       " ('B000050FDY', 4.8),\n",
       " ('B0002MQ9GK', 4.8),\n",
       " ('B000050B63', 4.8),\n",
       " ('B00027D5H6', 4.8)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_prediction(random.choice(train_user_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15c6b284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purchased:\n",
      "***Glitter Eyeshadow Diamond Dust Professional Grade 48 Color Day &amp; Night Eyeshadow 2 Palette Set\n",
      "***FOONEE Rhinestones Nail Art Gems Mixed Colours Shapes in Case (2mm,3000pcs)\n",
      "***Freeman Bare Foot Exfoliating foot scrub Peppermint and Plum 5.3 oz (Packs of 3)\n",
      "***Next Image/ON Organic Natural Hair Care Products Gift Set\n",
      "\n",
      "\n",
      "Recomendations:\n",
      "***Chialstar Lip Gloss Stick Makeup Waterproof Velvet Matte 24 Full Color Lipstick and Chialstar Storag\n",
      "***Italia Deluxe Ultra Fine Lip Liner set (Pack Of 12)\n",
      "***Liquid Lip Gloss Makeup With Applicator Wand In Long Lasting Glossy Gorgeous Colors - Lipstick &amp;\n",
      "***Sinful Colors Professional Nail Polish Enamel 56 Neon Melon\n",
      "***essie Gel Couture Nail Polish\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('B000050B65', 4.333333333333333),\n",
       " ('B000050FDY', 4.333333333333333),\n",
       " ('B0002MQ9GK', 4.333333333333333),\n",
       " ('B000050B63', 4.333333333333333),\n",
       " ('B00027D5H6', 4.333333333333333)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_prediction(random.choice(train_user_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8534d1e0",
   "metadata": {},
   "source": [
    "Вместе с рекомендацией вывела перечень рейтингов, большинтсву продуктов модель одинаковые рейтинги, но при этом смогла подобрать какие-то рекомендации. Порой странные, но вроде бы разные для всех тестовых пользователей. При предыдущем прогоне ноутбука у меня были для всех 3-х слечайно отобранных пользователей все одинаковые рекомендации.\n",
    "\n",
    "\n",
    "Посмотри, как будет работать готовая библиотека.\n",
    "\n",
    "\n",
    "## 2.2 Surprise\n",
    "\n",
    "Импортируем библиотеку и подготовим датасеты в том формате, которой для нее нужен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aea7cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "\n",
    "def data_preprocess(X,y):\n",
    "    X = X.copy()\n",
    "    X['rating'] = y\n",
    "    reader = surprise.Reader(line_format='user item rating', rating_scale=(1, 5))\n",
    "    dataset = surprise.Dataset.load_from_df(X[['user', 'item', 'rating']], reader)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = data_preprocess(X_train,y_train)\n",
    "test_dataset = data_preprocess(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f242c5",
   "metadata": {},
   "source": [
    "Создадим функцию, которая будет выводить результаты работы разных моделей из библиотеки surprise на нашем тестовом датасете и запустим ее на основных моделях с некими общими параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74042191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_predictions(model, trainset,testset):\n",
    "    train = trainset.build_full_trainset()\n",
    "    model.fit(train)\n",
    "    test = [testset.df.loc[i].to_list() for i in range(len(testset.df))]\n",
    "    y_pred = []\n",
    "    for prediction in model.test(test):\n",
    "        y_pred.append(prediction[3])\n",
    "    RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    MAE = mean_absolute_error(y_test, y_pred)\n",
    "    MAPE = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    R2 = r2_score(y_test, y_pred)\n",
    "    return RMSE, MAE, MAPE, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a121cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [surprise.BaselineOnly(),\n",
    "          surprise.SVD(n_factors=20, n_epochs=30, lr_all=0.005, reg_all=0.02, random_state=42),\n",
    "          surprise.SVDpp(n_factors=20, n_epochs=30, lr_all=0.005, reg_all=0.02, random_state=42),\n",
    "          surprise.SlopeOne(),\n",
    "          surprise.CoClustering(n_cltr_u = 6, n_cltr_i = 6, n_epochs=30, random_state=42),\n",
    "          surprise.KNNBaseline(k = 20, min_k = 2, user_based = True)\n",
    "         ]\n",
    "\n",
    "names = ['Baseline', 'SVD','SVD+', 'SlopeOne', 'CoClust', 'KNN_base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c8728e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working over model Baseline...\n",
      "Estimating biases using als...\n",
      "Working over model SVD...\n",
      "Working over model SVD+...\n",
      "Working over model SlopeOne...\n",
      "Working over model CoClust...\n",
      "Working over model KNN_base...\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>R2_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN_base</th>\n",
       "      <td>0.9303</td>\n",
       "      <td>0.5379</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.3080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.6361</td>\n",
       "      <td>0.2817</td>\n",
       "      <td>0.2684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD+</th>\n",
       "      <td>0.9709</td>\n",
       "      <td>0.6803</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>1.0073</td>\n",
       "      <td>0.5411</td>\n",
       "      <td>0.2363</td>\n",
       "      <td>0.1887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClust</th>\n",
       "      <td>1.0394</td>\n",
       "      <td>0.5956</td>\n",
       "      <td>0.2513</td>\n",
       "      <td>0.1362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>1.0428</td>\n",
       "      <td>0.7120</td>\n",
       "      <td>0.3217</td>\n",
       "      <td>0.1306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RMSE     MAE    MAPE  R2_score\n",
       "Test                                      \n",
       "KNN_base  0.9303  0.5379  0.2515    0.3080\n",
       "SVD       0.9566  0.6361  0.2817    0.2684\n",
       "SVD+      0.9709  0.6803  0.2878    0.2464\n",
       "SlopeOne  1.0073  0.5411  0.2363    0.1887\n",
       "CoClust   1.0394  0.5956  0.2513    0.1362\n",
       "Baseline  1.0428  0.7120  0.3217    0.1306"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores = pd.DataFrame()\n",
    "for name, model in zip(names, models):\n",
    "    print(f'Working over model {name}...')\n",
    "    RMSE, MAE, MAPE, R2 = list_predictions(model, train_dataset,test_dataset)\n",
    "    new_row = {'Test':name, \n",
    "               'RMSE':round(RMSE,4),\n",
    "               'MAE':round(MAE,4),\n",
    "               'MAPE': round(MAPE,4),\n",
    "               'R2_score': round(R2,4)\n",
    "               }\n",
    "    scores = scores.append(new_row, ignore_index=True)\n",
    "scores = scores.set_index('Test')\n",
    "display(scores.sort_values(by = 'RMSE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652b125",
   "metadata": {},
   "source": [
    "Для первых двух лучших алгоритмов попробуем подобрать параметры с помощью GridSearch. Интересно, что SVD+ только на 3-м месте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd4cccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8578258486849311\n",
      "\n",
      "{'n_factors': 100, 'n_epochs': 50, 'biased': True, 'init_mean': 0, 'init_std_dev': 0.1, 'lr_bu': 0.005, 'lr_bi': 0.005, 'lr_pu': 0.005, 'lr_qi': 0.005, 'reg_bu': 0.02, 'reg_bi': 0.02, 'reg_pu': 0.02, 'reg_qi': 0.02, 'random_state': 42, 'verbose': False, 'bsl_options': {}, 'sim_options': {'user_based': True}}\n",
      "Wall time: 8.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {'n_factors': [6, 10, 20, 40, 100], 'n_epochs': [50,], \n",
    "               'lr_all': [0.005, 0.001], 'reg_all': [0.05, 0.02],\n",
    "              'random_state': [42, ]\n",
    "             }\n",
    "\n",
    "gs_svd = surprise.model_selection.GridSearchCV(surprise.SVD, param_grid,\n",
    "                                               measures=[\"rmse\"], cv=5)\n",
    "\n",
    "gs_svd.fit(train_dataset)\n",
    "\n",
    "print(f'{gs_svd.best_score[\"rmse\"]}\\n')\n",
    "print(f'{vars(gs_svd.best_estimator[\"rmse\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f63ad4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "0.9248726021518057\n",
      "\n",
      "{'bsl_options': {}, 'sim_options': {'name': 'cosine', 'user_based': False}, 'verbose': True, 'k': 10, 'min_k': 2}\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = {'k': [5, 10, 20, 40], 'min_k': [2,], \n",
    "              'sim_options': {\n",
    "                  'name': ['cosine'],\n",
    "                  'user_based': [True, False]\n",
    "                  }\n",
    "             }\n",
    "\n",
    "gs_knn = surprise.model_selection.GridSearchCV(surprise.KNNBaseline, param_grid, \n",
    "                                           measures=[\"rmse\"], cv=5)\n",
    "\n",
    "gs_knn.fit(train_dataset)\n",
    "\n",
    "print(f'{gs_knn.best_score[\"rmse\"]}\\n')\n",
    "print(f'{vars(gs_knn.best_estimator[\"rmse\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4175d4a2",
   "metadata": {},
   "source": [
    "SVD при подборе параметров показал результат лучше. Посмотрим, что он покажет на кросс-валидации и на тестовом датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e98bd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8883  0.8526  0.8331  0.8234  0.9019  0.8599  0.0306  \n",
      "MAE (testset)     0.5432  0.5301  0.5131  0.5051  0.5496  0.5282  0.0170  \n",
      "Fit time          0.14    0.14    0.14    0.15    0.14    0.14    0.00    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.88829312, 0.85264969, 0.8331153 , 0.82335011, 0.90190201]),\n",
       " 'test_mae': array([0.54320292, 0.53007491, 0.51309192, 0.50507291, 0.54961298]),\n",
       " 'fit_time': (0.13899993896484375,\n",
       "  0.1379995346069336,\n",
       "  0.14002323150634766,\n",
       "  0.14989638328552246,\n",
       "  0.1379997730255127),\n",
       " 'test_time': (0.00699925422668457,\n",
       "  0.006999969482421875,\n",
       "  0.007999420166015625,\n",
       "  0.007999420166015625,\n",
       "  0.007999658584594727)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_best = surprise.SVD(n_factors = 100, n_epochs = 50, \n",
    "              lr_all = 0.005, reg_all = 0.02,\n",
    "              random_state = 42)\n",
    "surprise.model_selection.cross_validate(algo_best, train_dataset, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2c0f715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9165, MAE: 0.5595, MAPE: 0.2527, R2: 0.3284\n"
     ]
    }
   ],
   "source": [
    "RMSE, MAE, MAPE, R2 = list_predictions(algo_best, train_dataset,test_dataset)\n",
    "\n",
    "print(f'RMSE: {round(RMSE,4)}, MAE: {round(MAE,4)}, MAPE: {round(MAPE,4)}, R2: {round(R2,4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8dc1d3",
   "metadata": {},
   "source": [
    "Модель получилась немного переобученной, так как RMSE выше на тесте, чем на трейне. В целом результат в 2 раза лучше, чем в случае с коллоборативной фильтрацией.\n",
    "\n",
    "Следующий шаг - посмотрим, как она дает точечные предсказания для отдельных пользователей. Для этого воспользуемся функцией build_anti_testset в библиотеке. Эту функцию будем исползовать для всего набора данных. Она вернет сочетания пользователей, продуктов и рейтингов, которых нет в датасете. Посмотрим, какие рекомендации даст алгоритм для таких пользователей. Будем выводить список их покупок и рекомендаций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57a03233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31076676"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset = data_preprocess(df_modified[['user', 'item']],df_modified['rating'])\n",
    "trainset = total_dataset.build_full_trainset()\n",
    "testset = trainset.build_anti_testset()\n",
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fa582a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A141OPVE376YFI', 'B000050B63', 4.447254304237688),\n",
       " ('A141OPVE376YFI', 'B000068PBJ', 4.447254304237688),\n",
       " ('A141OPVE376YFI', 'B00005U8U8', 4.447254304237688),\n",
       " ('A141OPVE376YFI', 'B000068PBO', 4.447254304237688),\n",
       " ('A141OPVE376YFI', 'B000065AB1', 4.447254304237688),\n",
       " ('A141OPVE376YFI', 'B00005355V', 4.447254304237688),\n",
       " ('A141OPVE376YFI', 'B000068PBK', 4.447254304237688),\n",
       " ('A141OPVE376YFI', 'B00005354G', 4.447254304237688),\n",
       " ('A141OPVE376YFI', 'B000089SAQ', 4.447254304237688),\n",
       " ('A141OPVE376YFI', 'B00009RB14', 4.447254304237688)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33565360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def user_prediction(user):\n",
    "    purchase_list = df_modified[df_modified['user'] == user]['item'].values\n",
    "    print('Purchased:')\n",
    "    for item in purchase_list:\n",
    "        try:\n",
    "            print(f'***{desc[item][:100]}')\n",
    "        except:\n",
    "            print(item)\n",
    "            \n",
    "    testset_1 = (el for el in testset if el[0] == user)\n",
    "    predictions = algo_best.test(testset_1)\n",
    "    \n",
    "    top = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top[uid].append((iid, est))\n",
    "    for uid, user_ratings in top.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top[uid] = user_ratings\n",
    "        \n",
    "    print('\\n')\n",
    "    print(f'Recomendations:')\n",
    "\n",
    "    recomendations = [p[0] for p in top[user]][:5]\n",
    "\n",
    "    for recom in recomendations:\n",
    "           try:\n",
    "                print(f'***{desc[recom][:100]}')\n",
    "           except:\n",
    "                print(recom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98fec796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purchased:\n",
      "***Bonne Bell Smackers Bath and Body Starburst Collection\n",
      "***Bath &amp; Body Works Ile De Tahiti Moana Coconut Vanille Moana Body Wash with Tamanoi 8.5 oz\n",
      "***Bath &amp; Body Works Ile De Tahiti Moana Coconut Vanille Moana Body Wash with Tamanoi 8.5 oz\n",
      "***Fruits &amp; Passion Blue Refreshing Shower Gel - 6.7 fl. oz.\n",
      "***Yardley By Yardley Of London Unisexs Lay It On Thick Hand &amp; Foot Cream 5.3 Oz\n",
      "\n",
      "\n",
      "Recomendations:\n",
      "***Truefitt &amp; Hill Trafalgar After Shave Splash 100ml/3.38oz\n",
      "***Commonwealth Lavare Extra Large Pineapple Bath Soap 12 Oz. by CST\n",
      "***Paul Brown Hawaii Hapuna Hair Styling Paste, 8 Ounce\n",
      "***Boots No7 Moisture Quench Day Fluid 3.3 fl oz (100 ml)\n",
      "***Gillette All Over Clean Hair &amp; Body Wash 16 Fl Oz (Pack of 2)\n"
     ]
    }
   ],
   "source": [
    "total_users = df_modified['user'].unique()\n",
    "\n",
    "user_prediction(random.choice(total_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5c00212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purchased:\n",
      "***Citre Shine Moisture Burst Shampoo - 16 fl oz\n",
      "***Avalon Grapefruit and Geranium Smoothing Shampoo, 11 Ounce\n",
      "***Bonne Bell Smackers Bath and Body Starburst Collection\n",
      "***Bath &amp; Body Works Ile De Tahiti Moana Coconut Vanille Moana Body Wash with Tamanoi 8.5 oz\n",
      "***Bath &amp; Body Works Ile De Tahiti Moana Coconut Vanille Moana Body Wash with Tamanoi 8.5 oz\n",
      "\n",
      "\n",
      "Recomendations:\n",
      "***Rainbow Light - MintAsure Fresh Breath Capsules, Powerful Support for Healthy Teeth and Gums and Las\n",
      "***Neutrogena Ultra Sheer Dry-Touch Sunscreen Broad Spectrum SPF 70, 3 Fl. oz.\n",
      "*** Supernail China Silk Wrap, 72 Inch \n",
      "***EVO FLEX Sunnies Flexible Tanning Bed Goggles Eye Protection UV PINK Glasses\n",
      "***Pack of 6 Salon Sectioning Clip Clamp Hairdressing Styling Hair Tool Crocodile\n"
     ]
    }
   ],
   "source": [
    "user_prediction(random.choice(total_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f150a97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purchased:\n",
      "***Panasonic WES9839P Men's Electric Razor Replacement Inner Blade &amp; Outer Foil Set\n",
      "***Crest Pro-Health Clinical Deep Clean Mint Mouthwash 473 Ml\n",
      "***Dr. Bronner's Organic Castile Bar Soap - Almond - 5 oz.\n",
      "\n",
      "\n",
      "Recomendations:\n",
      "***Norelco 6826XL Quadra Action Cord/Cordless Rechargeable Men's Shaver\n",
      "***Fruits &amp; Passion Blue Refreshing Shower Gel - 6.7 fl. oz.\n",
      "***Yardley By Yardley Of London Unisexs Lay It On Thick Hand &amp; Foot Cream 5.3 Oz\n",
      "***bareMinerals Essential Brow Kit - Dark Blond/Medium Brown\n",
      "***Alpha Hydrox AHA Souffle Soothing Anti-Wrinkle 1.6 oz.\n"
     ]
    }
   ],
   "source": [
    "user_prediction(random.choice(total_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c318b",
   "metadata": {},
   "source": [
    "Итак, здесь предсказания для индивидуального пользователя уже намного лучше и можно сказать ей некий смысл в них (в последнем случае предлагают набор для окрашивания бровей пользователю, купившему съемные лезвия для бритв).Теперь я знаю, как появляются раздражащие рекомендации.\n",
    "\n",
    "Однако, как нам говорили на занятии, качество рекомендательной системы оценивается бизнес-метриками. Кроме того, на практике не используется один алгоритм, а несколько."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
